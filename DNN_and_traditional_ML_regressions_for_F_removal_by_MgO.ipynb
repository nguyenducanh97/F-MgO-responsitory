{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c350e76f",
      "metadata": {
        "id": "c350e76f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, multilabel_confusion_matrix, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "import joblib\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e193ff5",
      "metadata": {
        "id": "8e193ff5"
      },
      "outputs": [],
      "source": [
        "def data_prerocessing (Input,Output):\n",
        "    Input = Input/np.std(Input,axis = 0)\n",
        "    (qt,Removal,finalPH,LeachingMg) = (Output[:,0],Output[:,1],Output[:,2],Output[:,3])\n",
        "\n",
        "    fixpoint = dict(qt =  1.6675,\n",
        "                    Removal = np.std(Removal),\n",
        "                    finalPH = np.std(finalPH),\n",
        "                    LeachingMg = 2.56)\n",
        "\n",
        "    qt_processed = np.emath.logn(1.6675,qt)\n",
        "    Removal_processed = Removal/np.std(Removal)\n",
        "    finalPH_processed = finalPH/np.std(finalPH)\n",
        "    LeachingMg_processed = np.emath.logn(2.56,LeachingMg+1)\n",
        "    Output = np.stack((qt_processed,Removal_processed,finalPH_processed,LeachingMg_processed),axis = 1)\n",
        "\n",
        "    return (Input,Output,fixpoint)\n",
        "\n",
        "def cal_result(prediction,fix_point):\n",
        "\n",
        "    qt_result = np.power(fix_point['qt'],prediction[:,0])\n",
        "    Removal_result = prediction[:,1] * fix_point['Removal']\n",
        "    finalPH_result = prediction[:,2] * fix_point['finalPH']\n",
        "    LeachingMg_result = np.power(fix_point['LeachingMg'],prediction[:,3])-1\n",
        "    result = np.stack((qt_result,Removal_result,finalPH_result,LeachingMg_result),axis = 1)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PyVoGkaiX1qd"
      },
      "id": "PyVoGkaiX1qd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8547c583",
      "metadata": {
        "id": "8547c583"
      },
      "outputs": [],
      "source": [
        "#Loading data\n",
        "df= pd.read_csv('F-removal-by-MgO-data-321data-points.csv')\n",
        "data= pd.read_csv('F-removal-by-MgO-data-321data-points.csv')\n",
        "data = pd.DataFrame.to_numpy(data)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0328c6b0",
      "metadata": {
        "id": "0328c6b0"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing\n",
        "# Input of model\n",
        "X = data[:,0:15]\n",
        "# Output of model\n",
        "Y = data[:,15:19]\n",
        "X_,Y_ ,fix_point= data_prerocessing(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554d1f59",
      "metadata": {
        "id": "554d1f59"
      },
      "outputs": [],
      "source": [
        "# Split arrays or matrices into random train and test subset\n",
        "# Training 70%, testing 30%\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_, Y_, test_size=0.3, random_state=1)\n",
        "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Save original training and testing data sets\n",
        "tmp = np.concatenate((X_train_,y_train_),axis = 1)\n",
        "Train_data = pd.DataFrame(data = tmp, columns= df.columns.values)\n",
        "Train_data.to_csv(\"Training set-Data-for-F-MgO.csv\",index = None)\n",
        "\n",
        "tmp = np.concatenate((X_test_,y_test_),axis = 1)\n",
        "Test_data = pd.DataFrame(data = tmp, columns= df.columns.values)\n",
        "Test_data.to_csv(\"Testing set-Data-for-F-MgO.csv\",index = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e5472fc",
      "metadata": {
        "id": "6e5472fc"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the majority value for each column\n",
        "majority = df.mode().iloc[0]\n",
        "\n",
        "# calculate the number of data points that are different from the majority value in each column\n",
        "diff_counts = (df != majority).sum()\n",
        "\n",
        "# print the number of data points that are different from the majority value in each column\n",
        "print(diff_counts)"
      ],
      "metadata": {
        "id": "TLh-NgkCXnkj"
      },
      "id": "TLh-NgkCXnkj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7052b7",
      "metadata": {
        "scrolled": true,
        "id": "ea7052b7"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.figure(figsize = (20, 20))\n",
        "for i in range(19):\n",
        "    plt.subplot(4,5,i+1)\n",
        "    plt.plot(data[:,i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8550d3",
      "metadata": {
        "scrolled": true,
        "id": "3c8550d3"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation coefficient\n",
        "def corrfunc(x, y, **kws):\n",
        "    r, _ = stats.pearsonr(x, y)\n",
        "    ax = plt.gca()\n",
        "    ax.annotate(\"r = {:.2f}\".format(r),\n",
        "                xy=(.1, .6), xycoords=ax.transAxes,\n",
        "               size = 30)\n",
        "\n",
        "sns.set_context(font_scale=3)\n",
        "\n",
        "# Pair grid set up\n",
        "g = sns.PairGrid(df)\n",
        "\n",
        "# Scatter plot on the upper triangle\n",
        "g.map_upper(plt.scatter, s=12, color = 'gray')\n",
        "\n",
        "# Distribution on the diagonal\n",
        "#g.map_diag(sns.distplot, kde=False, color = 'blue')\n",
        "g.map_diag(plt.hist, color = 'gray')\n",
        "\n",
        "# Density Plot and Correlation coefficients on the lower triangle\n",
        "#g.map_lower(sns.kdeplot, cmap = cmap)\n",
        "g.map_lower(corrfunc);\n",
        "\n",
        "# Increase the size of x-axis and y-axis labels\n",
        "for ax in g.axes.flat:\n",
        "    ax.xaxis.label.set_size(25)\n",
        "    ax.yaxis.label.set_size(25)\n",
        "\n",
        "plt.savefig('Correlation Matrix Plot with R-score.png', dpi=500, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a516d4ad",
      "metadata": {
        "id": "a516d4ad"
      },
      "source": [
        "# Neural Network and Deep NN models for multiple regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dce688c8",
      "metadata": {
        "id": "dce688c8"
      },
      "source": [
        "# Type1: 1 Layer NN (Shallow NN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197e3837",
      "metadata": {
        "id": "197e3837"
      },
      "outputs": [],
      "source": [
        "def Shallow_NN(HiddenLayerNote=20,output_dim=4):\n",
        "    # Initialising the ANN\n",
        "    model = Sequential()\n",
        "\n",
        "    # Adding the input layer and the first hidden layer\n",
        "    model.add(Dense(HiddenLayerNote, activation='relu'))\n",
        "\n",
        "    # Adding the output layer\n",
        "    model.add(Dense(units = output_dim, activation='relu'))\n",
        "\n",
        "    # define opimizaion method\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    #define loss function\n",
        "    model.compile(optimizer=opt, loss=losses.MeanSquaredError())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba5fc3fc",
      "metadata": {
        "id": "ba5fc3fc"
      },
      "outputs": [],
      "source": [
        "ANN_model = Shallow_NN(HiddenLayerNote = 8)\n",
        "#ANN_model = Shallow_NN(HiddenLayerNote = 16)\n",
        "#ANN_model = Shallow_NN(HiddenLayerNote = 32)\n",
        "#ANN_model = Shallow_NN(HiddenLayerNote = 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df6e2b8a",
      "metadata": {
        "id": "df6e2b8a"
      },
      "source": [
        "# Type2: Deep NN (architecture #1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "750ad9c6",
      "metadata": {
        "scrolled": true,
        "id": "750ad9c6"
      },
      "outputs": [],
      "source": [
        "# Creating Deep neural network\n",
        "ANN_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=16, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=8, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=4, activation='relu'),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f2774cf",
      "metadata": {
        "id": "4f2774cf"
      },
      "source": [
        "# Type3: Deep NN (architecture #2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78bbbbcb",
      "metadata": {
        "scrolled": true,
        "id": "78bbbbcb"
      },
      "outputs": [],
      "source": [
        "# Creating Deep neural network\n",
        "Input = tf.keras.Input(shape=(None,15))\n",
        "X = tf.keras.layers.Dense(units=32, activation='sigmoid')(Input)\n",
        "X = tf.keras.layers.Dense(units=16, activation='relu')(X)\n",
        "X1 = tf.keras.layers.Dense(units=2, activation='relu')(X)\n",
        "X1 = tf.keras.layers.Dense(units=1, activation='relu')(X1)\n",
        "\n",
        "X2 = tf.keras.layers.Dense(units=2, activation='relu')(X)\n",
        "X2 = tf.keras.layers.Dense(units=1, activation='relu')(X2)\n",
        "\n",
        "X3 = tf.keras.layers.Dense(units=2, activation='relu')(X)\n",
        "X3 = tf.keras.layers.Dense(units=1, activation='relu')(X3)\n",
        "\n",
        "X4 = tf.keras.layers.Dense(units=2, activation='relu')(X)\n",
        "X4 = tf.keras.layers.Dense(units=1, activation='relu')(X4)\n",
        "Output = tf.keras.layers.Concatenate()([X1,X2,X3,X4])\n",
        "\n",
        "ANN_model = tf.keras.Model(Input,Output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "313326af",
      "metadata": {
        "id": "313326af"
      },
      "source": [
        "# Training model, Evaluation Prediction, Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df332b8",
      "metadata": {
        "id": "1df332b8"
      },
      "outputs": [],
      "source": [
        "# define opimizaion method\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "# define loss function\n",
        "ANN_model.compile(optimizer=opt, loss=losses.MeanSquaredError())\n",
        "\n",
        "# training model\n",
        "ANN_model.fit(X_train, y_train, validation_data = (X_test,y_test), batch_size=512, epochs=4000, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "764a18a6",
      "metadata": {
        "id": "764a18a6"
      },
      "outputs": [],
      "source": [
        "# re-training model\n",
        "# define opimizaion method\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "# define loss function\n",
        "ANN_model.compile(optimizer=opt, loss=losses.MeanSquaredError())\n",
        "ANN_model.fit(X_train, y_train, validation_data = (X_test,y_test),batch_size=512, epochs=4000, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab343889",
      "metadata": {
        "id": "ab343889"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "ANN_model.save('/content/drive/MyDrive/Colab Notebooks/save model/DNNmodel_32_16_4_4_4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "#Load model\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save model/ElasticNet Regression.pkl')\n",
        "model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save model/Extra Trees.pkl')\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save model/Random Forest.pkl')\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save model/Lasso.pkl')\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save modelBaggingRegressor.pkl')\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save modelKNeighborsRegressor.pkl')\n",
        "#ANN_model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/save model/DNN321684')\n",
        "#ANN_model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/save model/DNN3216421')"
      ],
      "metadata": {
        "id": "VAMp7AMqS7wP"
      },
      "id": "VAMp7AMqS7wP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf577de",
      "metadata": {
        "id": "faf577de"
      },
      "outputs": [],
      "source": [
        "# Change model\n",
        "predictions = model.predict(X_test)\n",
        "predictions = cal_result(predictions,fix_point)\n",
        "Y_t = cal_result(y_test,fix_point)\n",
        "y_test_f = np.ndarray.flatten(Y_t)\n",
        "predictions_f = np.ndarray.flatten(predictions)\n",
        "\n",
        "# Metrics\n",
        "mae = mean_absolute_error(y_test_f, predictions_f)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_f, predictions_f))\n",
        "R_score = r2_score(y_test_f, predictions_f)\n",
        "\n",
        "print([mae,rmse,R_score])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance"
      ],
      "metadata": {
        "id": "tvUrP06krtvc"
      },
      "id": "tvUrP06krtvc"
    },
    {
      "cell_type": "code",
      "source": [
        "def keras_scoring(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    return -mean_squared_error(y, y_pred)\n",
        "\n",
        "# Compute feature importance (change model)\n",
        "result = permutation_importance(model, X_test, y_test, scoring=keras_scoring, n_repeats=10, random_state=42)\n",
        "importances = result.importances_mean\n",
        "feature_importances = pd.DataFrame(data={'feature': range(X_train.shape[1]), 'importance': importances})\n",
        "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
        "\n",
        "# Convert importance column\n",
        "feature_importances['importance'] = feature_importances['importance'] / feature_importances['importance'].sum()\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "feature_importances.to_csv('/content/drive/MyDrive/Colab Notebooks/save model/FeImDNN.csv', index=False)"
      ],
      "metadata": {
        "id": "to5oQSaMP-87"
      },
      "id": "to5oQSaMP-87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing manually"
      ],
      "metadata": {
        "id": "rPuY-Phdr-zz"
      },
      "id": "rPuY-Phdr-zz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing data manually\n",
        "# Load the trained model from file\n",
        "model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/save model/ ')\n",
        "\n",
        "# Set the index for the row to be predicted\n",
        "row_index = 17  # replace with the desired index\n",
        "\n",
        "# Extract the input data for the selected row\n",
        "input_data = data[row_index, :15].reshape(1, 15)\n",
        "\n",
        "# Extract the output data for the selected row\n",
        "real_output_data = data[row_index, 15:]\n",
        "\n",
        "# Make a prediction using the loaded model\n",
        "predicted_output_data = model.predict(input_data)\n",
        "\n",
        "# Calculate the error between the predicted and real output data\n",
        "error = np.abs((predicted_output_data - real_output_data) / real_output_data * 100)\n",
        "\n",
        "# Display the predicted and real output data along with the error\n",
        "print(f'Input data: {input_data}')\n",
        "print(f'Real output data: {real_output_data}')\n",
        "print(f'Predicted output data: {predicted_output_data}')\n",
        "print(f'Error: {error}')"
      ],
      "metadata": {
        "id": "GhtQaw3cYD6Z"
      },
      "id": "GhtQaw3cYD6Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fbbd2b16",
      "metadata": {
        "id": "fbbd2b16"
      },
      "source": [
        "# Classical machine learning approaches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Classical ml models by training on training set and testing on testing set\n",
        "import joblib\n",
        "import sklearn\n",
        "def evaluate_classical_ML(X_train, X_test, y_train, y_test):\n",
        "    # Names of models\n",
        "    model_name_list = ['Multiple Linear Regression', 'ElasticNet Regression',\n",
        "                     'Random Forest', 'Extra Trees', 'Lasso', 'Ridge',\n",
        "                       'BaggingRegressor', 'KNeighborsRegressor']\n",
        "\n",
        "    # Instantiate the models\n",
        "    model1 = LinearRegression()\n",
        "    model2 = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
        "    model3 = RandomForestRegressor(n_estimators=10)\n",
        "    model4 = ExtraTreesRegressor(n_estimators=20)\n",
        "    model5 = Lasso(alpha=0.5)\n",
        "    model6 = Ridge(alpha=0.5)\n",
        "    model7 = sklearn.ensemble.BaggingRegressor(n_estimators=50)\n",
        "    model8 = sklearn.neighbors.KNeighborsRegressor()\n",
        "\n",
        "\n",
        "    # Dataframe for results\n",
        "    results = pd.DataFrame(columns=['mae', 'rmse', 'R-Squared'], index = model_name_list)\n",
        "    plt.figure(figsize = (16, 16))\n",
        "    plt.suptitle('Classical ML Predictions')\n",
        "\n",
        "\n",
        "    # Train and predict with each model\n",
        "    for i, model in enumerate([model1, model2, model3, model4,model5,model6, model7, model8]):\n",
        "        model.fit(X_train, y_train)\n",
        "        joblib.dump(model,'/content/drive/MyDrive/Colab Notebooks/save model'+ model_name_list[i]+'.pkl')\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "        # Calculate result\n",
        "        predictions = cal_result(predictions,fix_point)\n",
        "        Y_t = cal_result(y_test,fix_point)\n",
        "        y_test_f = np.reshape(Y_t,(384,1))\n",
        "        predictions_f = np.reshape(predictions,(384,1))\n",
        "\n",
        "        # Metrics\n",
        "        mae = mean_absolute_error(y_test_f, predictions_f)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test_f, predictions_f))\n",
        "        R_score = r2_score(y_test_f, predictions_f)\n",
        "\n",
        "        # Insert results into the dataframe\n",
        "        model_name = model_name_list[i]\n",
        "        results.loc[model_name, :] = [mae, rmse, R_score]\n",
        "\n",
        "        plt.subplot(4,3,i+1)\n",
        "        plt.plot(y_test_f, color = 'red', label = 'Real data')\n",
        "        plt.plot(predictions_f)\n",
        "        plt.legend(['Actual', model_name_list[i]], fontsize = 10)\n",
        "\n",
        "    plt.savefig('Classical ML Predictions.png', dpi=500, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "VRe9dsGRnBep"
      },
      "id": "VRe9dsGRnBep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    evaluate_classical_ML(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "dDeDDa_Qoch3"
      },
      "id": "dDeDDa_Qoch3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Predicted Data and Evaluating Models using Test Data"
      ],
      "metadata": {
        "id": "oZtD3PyjsjLC"
      },
      "id": "oZtD3PyjsjLC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set data\n",
        "# Load the trained model\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save model/ElasticNet Regression.pkl')\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save modelExtra Trees.pkl')\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save model/Random Forest.pkl')\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save model/Lasso.pkl')\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save modelBaggingRegressor.pkl')\n",
        "#model = joblib.load('/content/drive/MyDrive/Colab Notebooks/save modelKNeighborsRegressor.pkl')\n",
        "#ANN_model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/save model/DNN321684')\n",
        "ANN_model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/save model/DNN3216421')\n",
        "\n",
        "def get_predictions(ANN_model, X, y):\n",
        "    y_true = y_test_ if y is y_test_ else y_train_\n",
        "    y_pred = ANN_model.predict(X)\n",
        "    return y_pred, y_true\n",
        "\n",
        "y_pred, y_true = get_predictions(ANN_model, X_test, y_test_)\n",
        "#y_pred, y_true = get_predictions(ANN_model, X_train, y_train_)\n",
        "\n",
        "# Data processing\n",
        "y_pred = cal_result(y_pred,fix_point)\n",
        "output_data = {'qt': y_pred[:,0] , 'R': y_pred[:,1], 'finalpH' : y_pred[:,2], 'leachingMg': y_pred[:,3]}\n",
        "output_data = pd.DataFrame(data=output_data)\n",
        "output_path = '/content/drive/MyDrive/Colab Notebooks/save model/predict_test.csv'\n",
        "output_data.to_csv(output_path, index=False)\n",
        "\n",
        "# Calculate the evaluation metrics\n",
        "#y_pred_f = np.ndarray.flatten(y_pred)\n",
        "#y_true_f = np.ndarray.flatten(y_true)\n",
        "\n",
        "for index in range(4):\n",
        "    y_pred_f = y_pred[:,index]\n",
        "    y_true_f = y_true[:,index]\n",
        "    mae = mean_absolute_error(y_pred_f, y_true_f)\n",
        "    rmse = mean_squared_error(y_true_f, y_pred_f, squared=False)\n",
        "    r2 = r2_score(y_pred_f, y_true_f)\n",
        "\n",
        "    # Print the evaluation metrics\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"R2: {r2:.4f}\")\n",
        "    print(\"========================\")"
      ],
      "metadata": {
        "id": "-_UXLfrx1X9A"
      },
      "id": "-_UXLfrx1X9A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_f = np.ndarray.flatten(y_pred)\n",
        "y_true_f = np.ndarray.flatten(y_true)\n",
        "\n",
        "mae = mean_absolute_error(y_pred_f, y_true_f)\n",
        "rmse = mean_squared_error(y_true_f, y_pred_f, squared=False)\n",
        "r2 = r2_score(y_pred_f, y_true_f)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R2: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "g9h1Qm7TlSwr"
      },
      "id": "g9h1Qm7TlSwr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}